{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1661779759435,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "hvvpxJv3cArz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.image import ResizeMethod\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "TRAIN_DIR = \"/content/drive/MyDrive/Data/\"\n",
    "SCALE_FACTOR = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1661780340878,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "ioenFj07cxht"
   },
   "outputs": [],
   "source": [
    "def random_rotate(imgs):\n",
    "    \"\"\"Rotates Images by 90 degrees.\"\"\"\n",
    "\n",
    "    _rotated= []\n",
    "    for img in imgs:\n",
    "      # Outputs random values from uniform distribution in between 0 to 4\n",
    "      rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n",
    "      # Here rn signifies number of times the image(s) are rotated by 90 degrees\n",
    "      _rotated.append(tf.image.rot90(img, rn))\n",
    "\n",
    "    return _rotated\n",
    "\n",
    "def flip_left_right(imgs):\n",
    "    \"\"\"Flips Images to left and right.\"\"\"\n",
    "    _flipped= []\n",
    "    for img in imgs:\n",
    "      # Here rn signifies number of times the image(s) are rotated by 90 degrees\n",
    "      _flipped.append(tf.image.flip_left_right(img))\n",
    "\n",
    "    return _flipped\n",
    "\n",
    "def resize_bicubic(images, size):\n",
    "  \"\"\"Resizes images to the give size\n",
    "  \"\"\"\n",
    "  return tf.image.resize(\n",
    "    images,\n",
    "    size,\n",
    "    method=ResizeMethod.BICUBIC,\n",
    "    preserve_aspect_ratio=False,\n",
    "    antialias=False,\n",
    "    name=None\n",
    "    )\n",
    "\n",
    "def crop_resize(images, size):\n",
    "    \n",
    "    return tf.image.crop_and_resize(\n",
    "        image,\n",
    "        boxes,\n",
    "        box_indices,\n",
    "        crop_size,\n",
    "        method='bilinear',\n",
    "        extrapolation_value=0.0,\n",
    "        name=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1661780345377,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "84kPYiL8q7yu",
    "outputId": "92c6d243-aea2-415b-9e32-9fe57d84ba15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 23\n"
     ]
    }
   ],
   "source": [
    "def prepare_data (split=(0.7, 0.2, 0.1)):\n",
    "    \n",
    "    set14_path = os.path.join(\"./Data\",\"Set14/Set14\")\n",
    "    set5_path = os.path.join(\"./Data\",\"Set5/Set5\")\n",
    "    all_images = [np.array(Image.open(path.join(set14_path, name))) for name in os.listdir(set14_path)]\n",
    "    all_images += [np.array(Image.open(path.join(set5_path, name))) for name in os.listdir(set5_path)]\n",
    "\n",
    "    # shuffle, flip, rotate, bicubic down /up (low_res, high_res)\n",
    "    all_images += random_rotate(all_images)\n",
    "    all_images += flip_left_right(all_images)\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    # train_data\n",
    "    for img in all_images:\n",
    "            # downscale image by factor {SCALE_FACTOR}\n",
    "            \n",
    "            \n",
    "    # split into test / train\n",
    "    train, test = train_test_split(all_images, random_state=12, train_size= 0.7)\n",
    "    print(f\"{len(train)} {len(test)}\")\n",
    "\n",
    "prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1661774979750,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "pJ_WuamFcPr9"
   },
   "outputs": [],
   "source": [
    "def flip_left_right(lowres_img, highres_img):\n",
    "    \"\"\"Flips Images to left and right.\"\"\"\n",
    "\n",
    "    # Outputs random values from a uniform distribution in between 0 to 1\n",
    "    rn = tf.random.uniform(shape=(), maxval=1)\n",
    "    # If rn is less than 0.5 it returns original lowres_img and highres_img\n",
    "    # If rn is greater than 0.5 it returns flipped image\n",
    "    return tf.cond(\n",
    "        rn < 0.5,\n",
    "        lambda: (lowres_img, highres_img),\n",
    "        lambda: (\n",
    "            tf.image.flip_left_right(lowres_img),\n",
    "            tf.image.flip_left_right(highres_img),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def random_rotate(lowres_img, highres_img):\n",
    "    \"\"\"Rotates Images by 90 degrees.\"\"\"\n",
    "\n",
    "    # Outputs random values from uniform distribution in between 0 to 4\n",
    "    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n",
    "    # Here rn signifies number of times the image(s) are rotated by 90 degrees\n",
    "    return tf.image.rot90(lowres_img, rn), tf.image.rot90(highres_img, rn)\n",
    "\n",
    "\n",
    "def random_crop(lowres_img, highres_img, hr_crop_size=96, scale=4):\n",
    "    \"\"\"Crop images.\n",
    "\n",
    "    low resolution images: 24x24\n",
    "    hight resolution images: 96x96\n",
    "    \"\"\"\n",
    "    lowres_crop_size = hr_crop_size // scale  # 96//4=24\n",
    "    lowres_img_shape = tf.shape(lowres_img)[:2]  # (height,width)\n",
    "\n",
    "    lowres_width = tf.random.uniform(\n",
    "        shape=(), maxval=lowres_img_shape[1] - lowres_crop_size + 1, dtype=tf.int32\n",
    "    )\n",
    "    lowres_height = tf.random.uniform(\n",
    "        shape=(), maxval=lowres_img_shape[0] - lowres_crop_size + 1, dtype=tf.int32\n",
    "    )\n",
    "\n",
    "    highres_width = lowres_width * scale\n",
    "    highres_height = lowres_height * scale\n",
    "\n",
    "    lowres_img_cropped = lowres_img[\n",
    "        lowres_height : lowres_height + lowres_crop_size,\n",
    "        lowres_width : lowres_width + lowres_crop_size,\n",
    "    ]  # 24x24\n",
    "    highres_img_cropped = highres_img[\n",
    "        highres_height : highres_height + hr_crop_size,\n",
    "        highres_width : highres_width + hr_crop_size,\n",
    "    ]  # 96x96\n",
    "\n",
    "    return lowres_img_cropped, highres_img_cropped\n",
    "\n",
    "def resize_bicubic(images, size):\n",
    "  \"\"\"Resizes images to the give size\n",
    "  \"\"\"\n",
    "  return tf.image.resize(\n",
    "    images,\n",
    "    size,\n",
    "    method=ResizeMethod.BICUBIC,\n",
    "    preserve_aspect_ratio=False,\n",
    "    antialias=False,\n",
    "    name=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "executionInfo": {
     "elapsed": 1165,
     "status": "error",
     "timestamp": 1661773935880,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "24_ymrKdccT-",
    "outputId": "51cf1a72-6b22-46a5-f835-09f2560a9950"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-85f258b9cf46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_cache' is not defined"
     ]
    }
   ],
   "source": [
    "def dataset_object(dataset_cache, training=True):\n",
    "\n",
    "    ds = dataset_cache\n",
    "    ds = ds.map(\n",
    "        lambda lowres, highres: random_crop(lowres, highres, scale=4),\n",
    "        num_parallel_calls=AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    if training:\n",
    "        ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.map(flip_left_right, num_parallel_calls=AUTOTUNE)\n",
    "    # Batching Data\n",
    "    ds = ds.batch(16)\n",
    "\n",
    "    if training:\n",
    "        # Repeating Data, so that cardinality if dataset becomes infinte\n",
    "        ds = ds.repeat()\n",
    "    # prefetching allows later images to be prepared while the current image is being processed\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataset_object(train_cache, training=True)\n",
    "val_ds = dataset_object(val_cache, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 461,
     "status": "error",
     "timestamp": 1661773947956,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "yc_OrzlGce1F",
    "outputId": "36641d62-8cab-4b37-caba-d6105de92028"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-65f239e03661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlowres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Hight Resolution Images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "lowres, highres = next(iter(train_ds))\n",
    "\n",
    "# Hight Resolution Images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(highres[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(highres[i].shape)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Low Resolution Images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(lowres[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(lowres[i].shape)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def PSNR(super_resolution, high_resolution):\n",
    "    \"\"\"Compute the peak signal-to-noise ratio, measures quality of image.\"\"\"\n",
    "    # Max value of pixel is 255\n",
    "    psnr_value = tf.image.psnr(high_resolution, super_resolution, max_val=255)[0]\n",
    "    return psnr_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1684,
     "status": "ok",
     "timestamp": 1661773966862,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "SnKTEirTch9s"
   },
   "outputs": [],
   "source": [
    "class EDSRModel(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def predict_step(self, x):\n",
    "        # Adding dummy dimension using tf.expand_dims and converting to float32 using tf.cast\n",
    "        x = tf.cast(tf.expand_dims(x, axis=0), tf.float32)\n",
    "        # Passing low resolution image to model\n",
    "        super_resolution_img = self(x, training=False)\n",
    "        # Clips the tensor from min(0) to max(255)\n",
    "        super_resolution_img = tf.clip_by_value(super_resolution_img, 0, 255)\n",
    "        # Rounds the values of a tensor to the nearest integer\n",
    "        super_resolution_img = tf.round(super_resolution_img)\n",
    "        # Removes dimensions of size 1 from the shape of a tensor and converting to uint8\n",
    "        super_resolution_img = tf.squeeze(\n",
    "            tf.cast(super_resolution_img, tf.uint8), axis=0\n",
    "        )\n",
    "        return super_resolution_img\n",
    "\n",
    "\n",
    "# Residual Block\n",
    "def ResBlock(inputs):\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.Add()([inputs, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "# Upsampling Block\n",
    "def Upsampling(inputs, factor=2, **kwargs):\n",
    "    x = layers.Conv2D(64 * (factor ** 2), 3, padding=\"same\", **kwargs)(inputs)\n",
    "    x = tf.nn.depth_to_space(x, block_size=factor)\n",
    "    x = layers.Conv2D(64 * (factor ** 2), 3, padding=\"same\", **kwargs)(x)\n",
    "    x = tf.nn.depth_to_space(x, block_size=factor)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_model(num_filters, num_of_residual_blocks):\n",
    "    # Flexible Inputs to input_layer\n",
    "    input_layer = layers.Input(shape=(None, None, 3))\n",
    "    # Scaling Pixel Values\n",
    "    x = layers.Rescaling(scale=1.0 / 255)(input_layer)\n",
    "    x = x_new = layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "\n",
    "    # 16 residual blocks\n",
    "    for _ in range(num_of_residual_blocks):\n",
    "        x_new = ResBlock(x_new)\n",
    "\n",
    "    x_new = layers.Conv2D(num_filters, 3, padding=\"same\")(x_new)\n",
    "    x = layers.Add()([x, x_new])\n",
    "\n",
    "    x = Upsampling(x)\n",
    "    x = layers.Conv2D(3, 3, padding=\"same\")(x)\n",
    "\n",
    "    output_layer = layers.Rescaling(scale=255)(x)\n",
    "    return EDSRModel(input_layer, output_layer)\n",
    "\n",
    "\n",
    "model = make_model(num_filters=64, num_of_residual_blocks=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "error",
     "timestamp": 1661773985490,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "3p_6c9iNcmRE",
    "outputId": "272f7287-f2c4-430d-a9ef-1392651eeb61"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8f80915c6184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Compiling model with loss as mean absolute error(L1 Loss) and metric as psnr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim_edsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPSNR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Training for more epochs will improve results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PSNR' is not defined"
     ]
    }
   ],
   "source": [
    "# Using adam optimizer with initial learning rate as 1e-4, changing learning rate after 5000 steps to 5e-5\n",
    "optim_edsr = keras.optimizers.Adam(\n",
    "    learning_rate=keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "        boundaries=[5000], values=[1e-4, 5e-5]\n",
    "    )\n",
    ")\n",
    "# Compiling model with loss as mean absolute error(L1 Loss) and metric as psnr\n",
    "model.compile(optimizer=optim_edsr, loss=\"mae\", metrics=[PSNR])\n",
    "# Training for more epochs will improve results\n",
    "model.fit(train_ds, epochs=100, steps_per_epoch=200, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "error",
     "timestamp": 1661773996089,
     "user": {
      "displayName": "Sandeep Mahanty",
      "userId": "01889700912677560422"
     },
     "user_tz": -330
    },
    "id": "MjoX-aFgcrIs",
    "outputId": "00bf8109-4920-41ee-8c82-23bd0988996c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-548ba9e9f393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlowres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlowres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_results(lowres, preds):\n",
    "    \"\"\"\n",
    "    Displays low resolution image and super resolution image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(24, 14))\n",
    "    plt.subplot(132), plt.imshow(lowres), plt.title(\"Low resolution\")\n",
    "    plt.subplot(133), plt.imshow(preds), plt.title(\"Prediction\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for lowres, highres in val.take(10):\n",
    "    lowres = tf.image.random_crop(lowres, (150, 150, 3))\n",
    "    preds = model.predict_step(lowres)\n",
    "    plot_results(lowres, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIhC4JincttG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0NoIRGcJSL5t0kTJfiO69",
   "collapsed_sections": [],
   "mount_file_id": "1S0z287-cHGRz-SKJu2wkWdjaNGjGW5II",
   "name": "esr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
